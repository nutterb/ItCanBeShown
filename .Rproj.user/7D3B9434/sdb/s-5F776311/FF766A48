{
    "collab_server" : "",
    "contents" : "# Covariance\n\n## Definition of Covariance\n\nFor any two random variables $X$ and $Y$, the covariance of $X$ and $Y$ is defined as\n\n$$Cov(X,Y) = E[(X-\\mu_X)(Y-\\mu_Y)]$$\n\n## Theorems on Covariance\n\n### Theorem\n\nLet $X$ be a random variable.  Then\n$$Cov(X,X) = V(X)$$\n\n_Proof:_\n\n$$\\begin{align*}\nCov(X,X)\n\t&= E[(X-\\mu)(X-\\mu)] \\\\\n\t&= E[(X-\\mu)^2] \\\\\n\t&= V(X)\n\\end{align*}$$\n\n\n### Theorem\n\nLet $X$ and $Y$ be random variables.  Then\n\n$$Cov(X,Y) = E(XY)-E(X)E(Y)$$\n\n_Proof:_\n\n$$\\begin{align*}\nCov(X,Y)\n  &= E[(X-\\mu_x)(Y-\\mu_Y)] \\\\\n  &= E[XY - X\\mu_y - Y\\mu_X + \\mu_X\\mu_Y] \\\\\n  &= E(XY) - E(X)\\mu_Y - \\mu_XE(Y) + \\mu_X\\mu_Y \\\\\n  &= E(XY) - E(X)E(Y) - E(X)E(Y) + E(X)E(Y) \\\\\n  &= E(XY) - 2E(X)E(Y) + E(X)E(Y) \\\\\n  &= E(XY) - E(X)E(Y)\n\\end{align*}$$\n\n\n\n### Covariance2.3\n\nLet $X$ and $Y$ be random variables and let $a$ and $b$ be constants.  Then\n\n$$Cov(aX,bY) = abCov(X,Y)$$\n\n_Proof:_\n\n$$\\begin{align*}\nCov(aX,bY)\n\t&= E(aXbY) - E(aX)E(bY) \\\\\n  &= abE(XY) - abE(X)E(Y) \\\\\n\t&= ab[E(XY) - E(X)E(Y)] \\\\\n  &= abCov(X,Y)\n\\end{align*}$$\n\n\n### Theorem\n\nLet $X_1 , X_2 , \\ldots , X_n$ be random variables with $E(X_i) = \\mu_i$ for $i = 1,2,\\ldots,n$ and let $Y_1,Y_2,\\ldots,Y_m$ be random variables with $E(Y_j) = \\phi_j$ for $j=1,2,\\ldots,m$.  Also, let $a_1,a_2,\\ldots,a_n$ and $b_1,b_2,\\ldots,b_m$ be constants.\\\\\n\nIf $U_1 = \\sum\\limits_{i=1}^{n}a_iX_i$\n and $U_2 = \\sum\\limits_{i=1}^{m}b_iY_i$, then \n \n$$Cov(U_1,U_2) = \\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{m}a_ib_jCov(X_i,Y_j)$$\n\n_Proof:_\n\n$$\\begin{align*}\nCov(U_1,U_2)\n\t&= E[(U_1-E(U_1))(U_2-E(U_2))] \\\\\n  &= E\\Big[\\big(\\sum\\limits_{i=1}^{n}a_iX_i-\\sum\\limits_{i=1}^{n}a_i\\mu_i\\big)\n\t\t\\big(\\sum\\limits_{j=1}^{m}b_jY_j-\\sum\\limits_{j=1}^{m}b_j\\phi_j\\big)\\Big] \\\\\n  &= E\\Big[\\big(\\sum\\limits_{i=1}^{n}a_i(X_i-\\mu_i)\\big)\\big(\\sum\\limits_{j=1}^{m}b_j(Y_j-\\phi_j)\\big)\\Big] \\\\\n  &= E\\Big[\\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{m}a_ib_j(X_i-\\mu_i)(Y_j-\\phi_j)\\Big] \\\\\n  &= \\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{m}a_ib_jE[(X_i-\\mu_i)(Y_j-\\phi_j)] \\\\\n  &= \\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{m}a_ib_j\\ Cov(X_i,Y_j)\n\\end{align*}$$\n\n\n### Theorem\n\nLet $X_1,X_2,\\ldots,X_n$ be random variables with $E(X_i)=\\mu_i$ for $i=1,2,\\ldots,n$ and let $a_1,a_2,\\ldots,a_n$ be constants.  \n\nIf $Y = \\sum\\limits_{i=1}^{n}a_iX_i$ then\n\n$$V(Y) = \n  \\sum\\limits_{i=1}^{n}a_i^2V(X_i)+2\\sum\\limits_{\\ \\ i<}\\sum\\limits_{j\\ \\ }a_ia_jCov(X_i,X_j)$$\n\n_Proof:_\n\n$$\\begin{align*}\nV(Y)\n\t&= E[(Y-\\mu_Y)^2] \\\\\n\t&= E[(Y-\\mu_Y)(Y-\\mu_Y)] \\\\\n  &= E\\Big[\\big(\\sum\\limits_{i=1}^{n}a_iX_i-a_i\\mu_i\\big)\n      \\big(\\sum\\limits_{n=1}^{n}a_jX_j-a_j\\mu_j\\big)\\Big] \\\\\n  &= \\sum\\limits_{i=1}^{n}\\sum\\limits_{j=1}^{n}a_ia_jE[(X_i-\\mu_i)(X_j-\\mu_j)] \\\\\n  &= \\sum\\limits_{i=1}^{n}a_i^2Cov(X_i,X_i)+\n\t\t\\sum\\limits_{\\ \\ i\\neq}\\sum\\limits_{j\\ \\ \\ \\ }a_ia_jE[(X_i-\\mu_i)(X_j-\\mu_j)] \\\\\n  &= \\sum\\limits_{i=1}^{n}a_i^2V(X_i)+\n      2\\sum\\limits_{\\ \\ i<}\\sum\\limits_{j\\ \\ \\ \\ }a_ia_jCov(X_i,X_j)\n\\end{align*}$$\n\n",
    "created" : 1471135201770.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1931936106",
    "id" : "FF766A48",
    "lastKnownWriteTime" : 1471137424,
    "last_content_update" : 1471137424331,
    "path" : "~/GitHub/ItCanBeShown/Covariance.Rmd",
    "project_path" : "Covariance.Rmd",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}