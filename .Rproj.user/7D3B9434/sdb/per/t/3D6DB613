{
    "collab_server" : "",
    "contents" : "# Variance Parameter \n\n## Defining Variance With Expected Values\n\nIn the case of a discrete random variable, the variance is\n$$\\begin{align*} \n\\sigma^2\n\t&= \\sum\\limits_{x=0}^{\\infty}(x-\\mu)^2p(x) \\\\\n\t&= \\sum\\limits_{x=0}^{\\infty}(x^2-2\\mu x+\\mu^2)p(x) \\\\\n\t&= \\sum\\limits_{x=0}^{\\infty}(x^2p(x)-2\\mu x\\cdot p(x)+\\mu^2p(x)) \\\\\n  &= \\sum\\limits_{x=0}^{\\infty}x^2p(x)-\\sum\\limits_{x=0}^{\\infty}2\\mu x\\cdot p(x)\n\t\t+ \\sum\\limits_{x=0}^{\\infty}\\mu^2p(x) \\\\\n  &= \\sum\\limits_{x=0}^{\\infty}x^2p(x)-2\\mu\\sum\\limits_{x=0}^{\\infty}x\\cdot p(x)\n\t\t+ \\mu^2\\sum\\limits_{x=0}^{\\infty}p(x) \\\\\n  &= \\sum\\limits_{x=0}^{\\infty}x^2p(x)-2\\mu\\cdot\\mu+\\mu^2 \\\\\n\t&= \\sum\\limits_{x=0}^{\\infty}x^2p(x)-\\mu^2 \\\\\n\t&= E(X^2)-E(X)^2\\\\\n\\end{align*}$$\n\nIn the case of a continuous random variable, the variance is\n$$\\begin{align*}\n\\sigma^2 \n\t&= \\int\\limits_{-\\infty}^{\\infty}(x-\\mu)^2f(x)dx \\\\\n\t&= \\int\\limits_{-\\infty}^{\\infty}(x^2-2\\mu x+\\mu^2)f(x)dx \\\\\n  &= \\int\\limits_{-\\infty}^{\\infty}(x^2f(x)-2\\mu x\\cdot f(x)+\\mu^2f(x))dx \\\\\n  &= \\int\\limits_{-\\infty}^{\\infty}x^2f(x)dx-\\int\\limits_{-\\infty}^{\\infty}2\\mu x\\cdot f(x)dx\n\t\t+ \\int\\limits_{-\\infty}^{\\infty}\\mu^2f(x)dx \\\\\n  &= \\int\\limits_{-\\infty}^{\\infty}x^2f(x)dx-2\\mu\\int\\limits_{-\\infty}^{\\infty}x\\cdot f(x)dx\n\t\t+ \\mu^2\\int\\limits_{-\\infty}^{\\infty}f(x)dx \\\\\n  &= \\int\\limits_{-\\infty}^{\\infty}x^2f(x)dx-2\\mu\\cdot\\mu+\\mu^2 \\\\\n\t&= \\int\\limits_{-\\infty}^{\\infty}x^2f(x)dx-\\mu^2 \\\\\n\t&= E(X^2)-E(X)^2\n\\end{align*}$$\n\nIn general, these results may be summarized as follows:\n\n$$\\begin{align*}\n\\sigma^2\n\t&= E[(X-\\mu)^2] \\\\\n\t&= E[(X^2-2\\mu X+\\mu^2)] \\\\\n\t&= E(X^2) - E(2\\mu X) + E(\\mu^2) \\\\\n\t&= E(X^2) - 2\\mu E(X) + \\mu^2 \\\\\n  &= E(X^2) - 2\\mu\\cdot\\mu + \\mu^2 \\\\\n\t&= E(X^2) - 2\\mu^2 + \\mu \\\\\n  &= E(X^2) - \\mu^2 \\\\\n\t&= E(X^2) - E(X)^2\n\\end{align*}$$\n\n\n\n## Unbiased Estimator\n\n$$\\begin{align*}\nE\\Bigg(\\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n}\\Bigg)\n      \t&= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2\\Big) \\\\\n      \t&= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}(x_i^2-2\\bar x x_i+\\bar x^2)\\Big) \\\\\n        &= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2\n      \t\t- \\sum\\limits_{i=1}^{n}2\\bar x x_i+\\sum\\limits_{i=1}^{n}\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-2\n      \t          \\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\sum\\limits_{i=1}^{n}\t+ n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-2\n      \t          \\frac{\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n}+n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-2\n      \t          \\frac{n(\\sum\\limits_{i=1}^{n}x_i)^2}{n^2}+n\\bar x^2\\Big) \\\\\n        &= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-2n\\bar x^2+n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2\\Big)-E(n\\bar x^2) \\\\\n        &= \\frac{1}{n}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2)-nE(\\bar x^2)\\Big) \\\\\n      \t&= \\frac{1}{n}\\Big[\\sum\\limits_{i=1}^{n}E(x_i^2)-nE(\\bar x^2)\\Big] \\\\\n^{[1]}  &= \\frac{1}{n}\\Big[\\sum\\limits_{i=1}^{n}\\Big(\\sigma^2+\\mu^2\\Big) - nE(\\bar x^2)\\Big] \\\\\n^{[2]}  &= \\frac{1}{n}\\Big[\\sum\\limits_{i=1}^{n}\\Big(\\sigma^2+\\mu^2\\Big) - \n            n(\\frac{\\sigma^2}{n}+\\mu^2)\\Big]\\\\\\\\\n        &= \\frac{1}{n}(n\\sigma^2-n\\mu^2+\\sigma^2-n\\mu^2) \\\\\n        &=\\frac{1}{n}(n\\sigma^2-\\sigma) \\\\\n        &= \\frac{1}{n}(n-1)\\sigma^2 \\\\\n        &= \\frac{n-1}{n}\\sigma^2\n\\end{align*}$$\n\n> 1. $V(X)=E(X^2)-E(X)^2$  \n>    $\\ \\ \\ \\ \\Rightarrow E(X^2)=V(X)+E(X)^2=\\sigma^2+\\mu^2$\n>    $V(\\bar X)=E(\\bar X^2)-E(\\bar X)^2$  \n>    $\\ \\ \\ \\ \\Rightarrow E(\\bar X^2)=V(\\bar X)+E(\\bar X)^2 = \\frac{\\sigma^2}{n}+\\mu^2$\n> 2. By the Central Limit Theorem, $V(\\bar X)=\\frac{\\sigma^2}{n}$\n\nSince $E\\Bigg(\\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n}\\Bigg)\\neq\\sigma^2$ it is a biased estimator.  Notice, however, that the bias can be eliminated by dividing by $n-1$ instead of by $n$\n\n$$\\begin{align*} \nE\\Bigg(\\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n-1}\\Bigg)\n      \t&= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2\\Big) \\\\\n      \t&= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}(x_i^2-2\\bar x x_i+\\bar x^2)\\Big) \\\\\n        &= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2\n      \t\t- \\sum\\limits_{i=1}^{n}2\\bar x x_i+\\sum\\limits_{i=1}^{n}\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n-1}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2 -\n      \t            2\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\sum\\limits_{i=1}^{n} + n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n-1}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-\n      \t      2\\frac{(\\sum\\limits_{i=1}^{n}x_i)^2}{n}+n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n-1}\n      \t    E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-\n      \t      2\\frac{n\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n^2} + n\\bar x^2\\Big) \\\\\n        &= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-2n\\bar x^2+n\\bar x^2\\Big) \\\\\n      \t&= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2-n\\bar x^2\\Big) \\\\\n        &= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2\\Big)-E(n\\bar x^2) \\\\\n        &= \\frac{1}{n-1}E\\Big(\\sum\\limits_{i=1}^{n}x_i^2\\Big)-nE(\\bar x^2) \\\\\n      \t&= \\frac{1}{n-1}\\Big[\\sum\\limits_{i=1}^{n}E(x_i^2)-nE(\\bar x^2)\\Big] \\\\\n^{[1]}  &= \\frac{1}{n-1}\\Big[\\sum\\limits_{i=1}^{n}(\\sigma^2+\\mu^2)-nE(\\bar x^2)\\Big] \\\\\n^{[2]}\t&= \\frac{1}{n-1}\\Big[\\sum\\limits_{i=1}^{n}(\\sigma^2+\\mu^2) -\n                n(\\frac{\\sigma^2}{n}+\\mu^2)\\Big] \\\\\n        &= \\frac{1}{n-1}(n\\sigma^2-n\\mu^2+\\sigma^2-n\\mu^2) \\\\\n        &= \\frac{1}{n}(n\\sigma^2-\\sigma) \\\\\n        &= \\frac{1}{n-1}(n-1)\\sigma^2 \\\\\n        &= \\frac{n-1}{n-1}\\sigma^2 \\\\\n        &=\\sigma^2\n\\end{align*}$$\n\n> 1. $V(X)=E(X^2)-E(X)^2$  \n>    $\\ \\ \\ \\ \\Rightarrow E(X^2)=V(X)+E(X)^2=\\sigma^2+\\mu^2$\n>    $V(\\bar X)=E(\\bar X^2)-E(\\bar X)^2$  \n>    $\\ \\ \\ \\ \\Rightarrow E(\\bar X^2)=V(\\bar X)+E(\\bar X)^2 = \\frac{\\sigma^2}{n}+\\mu^2$\n> 2. By the Central Limit Theorem, $V(\\bar X)=\\frac{\\sigma^2}{n}$\n\nThus $E\\Bigg(\\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n-1}\\Bigg)$ is an unbiased estimator of $\\sigma^2$, and we define the estimator \n\n$$s^2= \\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n-1}$$\n\n## Computational Formulae\n\n### Computational Formula for $\\sigma$^2 {#computational-formula-population-variance}\n\n$$\\begin{align*} \n\\sigma^2\n\t&= \\frac{\\sum\\limits_{i=1}^{N}(x_i-\\mu)^2}{N} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{N}x_i^2-\\frac{\\Big(\\sum\\limits_{i=1}^{N}x_i\\Big)^2}{N}}{N}\n\\end{align*}$$\n\n_Proof:_\n\n$$\\begin{align*} \n\\frac{\\sum\\limits_{i=1}^{N}(x_i-\\mu)^2}{N}\n\t&= \\frac{\\sum\\limits_{i=1}^{N}(x_i^2-2\\mu x_i+\\mu^2)}{N} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{N}\n\t          x_i^2-\\sum\\limits_{i=1}^{N}2\\mu x_i\n\t          + \\sum\\limits_{i=1}^{N}\\mu^2}{N}  \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{N}\n\t          x_i^2-2\\mu\\sum\\limits_{i=1}^{N}x_i+N\\mu^2}{N} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{N}x_i^2\n\t          -2\\frac{\\sum\\limits_{i=1}^{N}x_i}{N}\\sum\\limits_{i=1}^{N}x_i\n\t\t        + N\\Big(\\frac{\\sum\\limits_{i=1}^{N}x_i}{N}\\Big)^2}{N} \\\\\n  &= \\frac{\\sum\\limits_{i=1}^{N}\n            x_i^2-2\\frac{\\Big(\\sum\\limits_{i=1}^{N}x_i\\Big)^2}{N}\n            + \\frac{\\Big(\\sum\\limits_{i=1}^{N}x_i\\Big)^2}{N}}{N} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{N}x_i^2-\\frac{\\Big(\\sum\\limits_{i=1}^{N}x_i\\Big)^2}{N}}{N}\n\\end{align*}$$\n\n\n\n### Computational Formula for $s$^2 {#computational-formula-sample-variance}\n\n$$\\begin{align*} \ns^2\n\t&= \\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n-1} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-\\frac{\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n}}{n-1}\n\\end{align*}$$\n\n_Proof:_\n\n$$\\begin{align*} \n\\frac{\\sum\\limits_{i=1}^{n}(x_i-\\bar x)^2}{n-1}\n\t&= \\frac{\\sum\\limits_{i=1}^{n}(x_i^2-2\\bar x x_i+\\bar x^2)}{n-1} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-\\sum\\limits_{i=1}^{n}2\\bar x x_i\n\t\t+ \\sum\\limits_{i=1}^{n}\\bar x^2}{n-1} \\\\\n  &= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-2\\bar x\\sum\\limits_{i=1}^{n}x_i+n\\bar x^2}{n-1} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-2\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\sum\\limits_{i=1}^{n}x_i\n\t\t+ n\\Big(\\frac{\\sum\\limits_{i=1}^{n}x_i}{n}\\Big)^2}{n-1} \\\\\n  &= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-2\\frac{\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n}\n\t\t+ \\frac{\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n}}{n-1} \\\\\n\t&= \\frac{\\sum\\limits_{i=1}^{n}x_i^2-\\frac{\\Big(\\sum\\limits_{i=1}^{n}x_i\\Big)^2}{n}}{n-1}\n\\end{align*}$$\n",
    "created" : 1471085894444.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3760786410",
    "id" : "3D6DB613",
    "lastKnownWriteTime" : 1471085927,
    "last_content_update" : 1471085927544,
    "path" : "~/GitHub/ItCanBeShown/Variance.Rmd",
    "project_path" : "Variance.Rmd",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}