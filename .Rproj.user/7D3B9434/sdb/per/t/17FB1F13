{
    "collab_server" : "",
    "contents" : "# Chebychev's Theorem\n\n## Chebychev's Theorem\n\nIn any finite set of numbers and for any real number $h > 1$, at least $(1 - \\frac{1}{h^2}) \\cdot 100\\%$ of the numbers lie within $h$ standard deviations of the mean.  In other words, they lie within the interval $(\\mu-h\\cdot\\sigma , \\mu+h\\cdot\\sigma)$.\n\n_Proof:_\n\nFor a set $\\{x_1,x_2,\\ldots,x_r,x_{r+1},\\ldots,x_n\\}$ where, by choice of labeling, $\\{x_1,x_2,\\ldots,x_r\\}$ lie outside of $(\\mu-h\\cdot\\sigma , \\mu+h\\cdot\\sigma)$.  Also, $\\{x_{r+1},\\ldots,x_n\\}$ are within the interval.  Under these conditions we know\n\n$$|x_1-\\mu| > h\\sigma,\\ |x_2-\\mu| > h\\sigma, \\ldots,\\ |x_r-\\mu| > h\\sigma$$\n\nSquaring gives\n\n$$(x_1-\\mu)^2 > h^2\\sigma^2,\\ (x_2-\\mu)^2 > h^2\\sigma^2,\\ldots,\\ (x_r-\\mu)^2 > h^2\\sigma^2\\\\\n\\ \\ \\ \\ \\Rightarrow\\sum\\limits_{i=1}^{r}(x_1-\\mu)^2 > \\sum\\limits_{i=1}^{r}h^2\\sigma^2\n\t= rh^2\\sigma^2\n$$\n\nSince all $(x_i-\\mu)^2$ must necessarily be positive,\n\n$$\\begin{align*}\n\\sum\\limits_{i=1}^{r}(x_i-\\mu)^2 &< \\sum\\limits_{i=1}^{n}(x_i-\\mu)^2 \\\\\n\\ \\ \\ \\ \\Rightarrow rh^2\\sigma^2 &< \\sum\\limits_{i=1}^{n}(x_i-\\mu)^2 \\\\\n\\ \\ \\ \\ ^{[1]} \\Rightarrow rh^2\\sigma^2 &< n\\sigma^2 \\\\\n\\ \\ \\ \\ \\Rightarrow rh^2 &< n \\\\\n\\ \\ \\ \\ \\Rightarrow\\frac{r}{n} &< \\frac{1}{h^2}\n\\end{align*}$$\n\n> 1. $\\sigma^2 = \\frac{1}{n}\\sum\\limits_{i=1}^{n}(x_i-\\mu)^2$  \n>\t\t $\\ \\ \\ \\ \\Rightarrow n\\sigma^2 = \\sum\\limits_{i=1}^{n}(x_i-\\mu)^2$\n\nand $\\frac{r}{n}$ is the fraction of numbers outside $(\\mu-h\\cdot\\sigma , \\mu+h\\cdot\\sigma)$.  By the law of complements, the fraction of numbers inside the interval is $1 - \\frac{r}{n}$, which implies $1 - \\frac{r}{n} > 1 - \\frac{1}{h^2}$.  Thus, more than $(1-\\frac{1}{h^2})\\cdot 100\\%$ of the points lie within $h$ standard deviations of the mean, or within the interval $(\\mu-h\\cdot\\sigma , \\mu+h\\cdot\\sigma)$. \n\n\n## Alternate Proof of Chebychev's Theorem\n\nIn any finite set of numbers and for any real number $h>1$, at least $(1-\\frac{1}{h^2})\\cdot 100\\%$ of the numbers lie within $h$ standard deviations of the mean.  In other words, they lie within the interval $(\\mu-h\\cdot\\sigma,\\mu+h\\cdot\\sigma)$.\\\\\n\n_Proof:_\n\nThe proof here is done for the discrete case, but is applicable also in the continuous case by replacing the summations with integrals (with integrals, the limits will be from $-\\infty$ to $\\infty$).\n\n$$\\begin{align*}\n\\sigma^2\n\t&= E(x-\\mu)^2 \\\\\n\t&= \\sum\\limits_{y=0}^{\\infty}(y-\\mu)^2p(y) \\\\\n  &= \\sum\\limits_{y=0}^{\\mu-h\\sigma}(y-\\mu)^2p(y) + \n        \\sum\\limits_{y=\\mu-h\\sigma+1}^{\\mu+h\\sigma-1}(y-\\mu)^2p(y)\n\t\t    + \\sum\\limits_{y=\\mu+h\\sigma}^{\\infty}(y-\\mu)^2p(y) \\\\\n^{[1]} \\Rightarrow \\sigma^2 &\\geq \\sum\\limits_{y=0}^{\\mu-h\\sigma}(y-\\mu)^2p(y)\n\t\t+ \\sum\\limits_{y=\\mu+h\\sigma}^{\\infty}(y-\\mu)^2p(y)\\\\\n\\end{align*}$$\n\n> 1. Since all the $(y-\\mu)^2$ must be positive, removing the middle term will surely result in this inequality.\n\nIn both of these summations $y$ is outside the interval $(\\mu-h\\cdot\\sigma , \\mu+h\\cdot\\sigma)$, so\n\n$$\\begin{align*}\n              |y-\\mu|   &\\geq   h\\sigma \\\\\n\\Rightarrow (y-\\mu^2)   &\\geq   h^2\\sigma^2 \\\\\n\\Rightarrow \\sigma^2    &\\geq   \\sum\\limits_{y=0}^{\\mu-h\\sigma}h^2\\sigma^2p(y)\n\t\t+ \\sum\\limits_{\\mu+h\\sigma}^{\\infty}h^2\\sigma^2p(y) \\\\\n\\Rightarrow\\sigma^2     &\\geq   h^2\\sigma^2\\Big[\\sum\\limits_{y=0}^{\\mu-h\\sigma}p(y)\n\t\t+ \\sum\\limits_{\\mu+h\\sigma}^{\\infty}p(y)\\Big]\n\\end{align*}$$\n\nThe first summation is the sum of all probabilities that $y-\\mu < h\\sigma$, i.e. $P(y-\\mu < h\\sigma)$.  Likewise, the second summation is $P(y-\\mu > h\\sigma)$.\n\n$$\\begin{align*} \n\\Rightarrow \\sigma^2         &\\geq   h^2\\sigma^2[P(y-\\mu<h\\sigma) + P(y-\\mu>h\\sigma)] \\\\\n\\Rightarrow \\sigma^2         &\\geq   h^2\\sigma^2[P(|y-\\mu|>h\\sigma)] \\\\\n\\Rightarrow \\frac{1}{h^2}    &\\geq   P(|y-\\mu|>h\\sigma) \\\\\n\\Rightarrow 1-\\frac{1}{h^2}  &\\leq   P(|y-\\mu|>h\\sigma)\n\\end{align*}$$\n\n\n## Chebychev's Theorem for Absolute Deviation\n\nThis theorem is provided by Brunette \\cite{Brunetb}\n\nIn any finite set of numbers, and for any real number $h > 1$, at least $1 - \\frac{1}{h}$ of the numbers lie within $h$ absolute deviations of the mean, where the absolute deviation is defined $Ab = \\frac{1}{n}\\sum\\limits_{i=1}{n}|x_i-\\bar x|$.  In other words, $1-\\frac{1}{h}$ of the numbers are in the interval $(\\bar x-h\\cdot Ab , \\bar x+h\\cdot Ab)$.\n\n_Proof:_\n\nFor a set $\\{x_1,x_2,\\ldots,x_r,x_{r+1},\\ldots,x_n\\}$ where, by choice of labeling, $\\{x_1,x_2,\\ldots,x_r\\}$ lie outside of $(\\mu-h\\cdot Ab , \\mu+h\\cdot Ab)$.  Also, $\\{x_{r+1},\\ldots,x_n\\}$ are within the interval.  Accordingly,\n\n\n$$h \\cdot Ab \\leq |x_1-\\bar x| ,\\ h \\cdot Ab \\leq |x_1-\\bar x| ,\\ldots ,\\ h \\cdot Ab \n    \\leq |x_1-\\bar x| $$\n    \n$$\\begin{align*}\n\\Rightarrow r \\cdot h \\cdot Ab \n    &\\leq \\sum\\limits_{i=1}^{r}|x_i-\\bar x| \\\\\n\\Rightarrow r \\cdot h \\cdot Ab \n    &\\leq \\sum\\limits_{i=1}^{n}|x_i-\\bar x| \\\\\n^{[1]} \\Rightarrow r \\cdot h \\cdot Ab \n    &\\leq n \\cdot Ab\\\\\n\\Rightarrow \\frac{r}{n} \n    &\\leq \\frac{1}{h}\\\\\n\\Rightarrow -\\frac{r}{n} \n    &\\geq -\\frac{1}{h}\\\\\n\\Rightarrow 1-\\frac{r}{n} \n    &\\geq 1-\\frac{1}{h}\n\\end{align*}$$\n\n> 1. $Ab = \\frac{1}{n}\\sum\\limits_{i=1}^{n}|x_i-\\bar x|$  \n>    $\\Rightarrow n \\cdot Ab = \\sum\\limits_{i=1}^{n}|x_i-\\bar x|$ \n\nNow $\\frac{r}{n}$ is the fraction of numbers outside the interval.  So $1-\\frac{r}{n}$ is the fraction of numbers within $h$ absolute deviations of the mean, or within the interval $(\\mu-h\\cdot Ab , \\mu+h\\cdot Ab)$.\n\n",
    "created" : 1471048924101.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1102123203",
    "id" : "17FB1F13",
    "lastKnownWriteTime" : 1471050466,
    "last_content_update" : 1471050466445,
    "path" : "~/GitHub/ItCanBeShown/Chebychev.Rmd",
    "project_path" : "Chebychev.Rmd",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}